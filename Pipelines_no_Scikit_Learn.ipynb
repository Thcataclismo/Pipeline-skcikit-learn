{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1QNNS7QZrUlZCOpzNZ7bLKa005-S5c0xN",
      "authorship_tag": "ABX9TyM+Z8s4z9GIEAm2vJRuLyjw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Thcataclismo/Pipeline-skcikit-learn/blob/main/Pipelines_no_Scikit_Learn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pipelines no Scikit-Learn**"
      ],
      "metadata": {
        "id": "8rEzm-FMlvWr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.kaggle.com/datasets/jamesleslie/titanic-cleaned-data"
      ],
      "metadata": {
        "id": "jSOJPCe2ltJh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A classe Pipeline é uma funcionalidade do Scikit-Learn que ajuda criar códigos que possuam um padrão que possa ser facilmente entendido e compartilhando entre times de cientista e engenheiro de dados."
      ],
      "metadata": {
        "id": "ktgbLKpSlE6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade category_encoders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sr_m6z4ygNrt",
        "outputId": "8bf36bc2-512f-4d62-ead5-bc06d99c47b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting category_encoders\n",
            "  Downloading category_encoders-2.5.1.post0-py2.py3-none-any.whl (72 kB)\n",
            "\u001b[K     |████████████████████████████████| 72 kB 939 kB/s \n",
            "\u001b[?25hRequirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.8/dist-packages (from category_encoders) (0.5.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.8/dist-packages (from category_encoders) (1.0.2)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.8/dist-packages (from category_encoders) (1.3.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from category_encoders) (1.7.3)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from category_encoders) (0.12.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from category_encoders) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.5->category_encoders) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.0->category_encoders) (3.1.0)\n",
            "Installing collected packages: category-encoders\n",
            "Successfully installed category-encoders-2.5.1.post0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ib6ymkLnfvSJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from category_encoders import OneHotEncoder\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_validate\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lendo o dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/archive (3)/train_clean.csv\")"
      ],
      "metadata": {
        "id": "0OWzY2sWgWSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# retirando colunas com nome, ingresso e cabine dos conjuntos\n",
        "df.drop([\"Name\", \"Ticket\", \"Cabin\"], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "KmtB2OlKiAMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dividindo em conjunto de treino e test\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.drop(['Survived'], axis=1), \n",
        "                                                    df['Survived'], \n",
        "                                                    test_size=0.2, \n",
        "                                                    random_state=42)"
      ],
      "metadata": {
        "id": "ubMmIzmwiT9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# criando o modelo usando pipeline\n",
        "model = Pipeline(steps=[\n",
        "    ('one-hot encoder', OneHotEncoder()),\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('tree', DecisionTreeClassifier(max_depth=3, random_state=0))\n",
        "])"
      ],
      "metadata": {
        "id": "xMYGzS3qiWJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# treinando o modelo\n",
        "model.fit(X_train, y_train)\n",
        "train_score = model.score(X_train, y_train)"
      ],
      "metadata": {
        "id": "U9G2wyt2iX9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### quando chamamos o método fit, todos os passos definidos no Pipeline serão executados na ordem em que aparecem.\n",
        "\n"
      ],
      "metadata": {
        "id": "jdYBR9p3ldkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# avaliando o modelo\n",
        "test_score = model.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "37d2u8AjiZ5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train score: {}\".format(train_score))\n",
        "print(\"Test score: {}\".format(test_score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFddbSjnicfG",
        "outputId": "ca6dfcfe-dfaf-4025-8849-7c926ae189e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score: 0.8356741573033708\n",
            "Test score: 0.8156424581005587\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### No Pipeline acima, primeiro aplicamos o OneHotEncoder do pacote category_encoders. Esse transformador irá pegar todas as variáveis categóricas dos dados e aplicar a transformação. O segundo passo do Pipeline é a imputação de valores faltantes em variáveis númericas pela substituição dos valores faltantes pela média. O terceiro e último passo é uma árvore de decisão que será treinada nos dados pré-processados nos passos anteriores."
      ],
      "metadata": {
        "id": "LaRG0rCGlQos"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Cross-Validation com Pipelines***"
      ],
      "metadata": {
        "id": "CbS016oJifKv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Uma grande vantagem de usar o Pipeline é a possibilidades de incluí-los no esquema de cross-validation do seu modelo. "
      ],
      "metadata": {
        "id": "MQukGqB7k7mO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# validando o modelo usando 5-fold cross-validation\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "results = cross_validate(model, X=df.drop(['Survived'], axis=1), y=df['Survived'], cv=kfold)\n",
        "print(\"Average accuracy: %f (%f)\" %(results['test_score'].mean(), results['test_score'].std()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18AI6fcNixOz",
        "outputId": "4fca671e-6158-4a42-b593-d23ab13aaa8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average accuracy: 0.823803 (0.024182)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Perceba como, uma vez que você encapsulou todo o seu modelo dentro de um Pipeline, fica muito mais fácil validá-lo de forma correta e confiável. De forma bastante explícita, com o Pipeline o seu modelo não consiste apenas do algoritmo, mas também de todo o pré-processamento usado antes de aplicar o algoritmo nos dados."
      ],
      "metadata": {
        "id": "qnCD1OV3i64G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Grid-Search com Pipelines*** (hiperparâmetros)"
      ],
      "metadata": {
        "id": "ruI2QcsEjEGA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Uma vez que o pipeline está criado, podemos também facilmente realizar uma tunagem de hiperparâmetro utilizando o GridSearchCV. O pipeline basicamente se torna o nosso modelo, logo, basta apenas definirmos o tipo de validação desejada e os parâmetros que deverão ser tunados. "
      ],
      "metadata": {
        "id": "h_ZWl6PckyN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "ZRkSoi23jVtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tunando hiperparâmetros com 5-fold cross-validation e pipelines\n",
        "parameters = {'tree__max_depth': [3, 4, 5]}\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "grid = GridSearchCV(model, param_grid=parameters, cv=kfold, n_jobs=-1)\n",
        "grid.fit(X=df.drop(['Survived'], axis=1), y=df['Survived'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WopG82JjbTe",
        "outputId": "7ba7cce3-7317-4565-ecac-7a32630d30ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),\n",
              "             estimator=Pipeline(steps=[('one-hot encoder', OneHotEncoder()),\n",
              "                                       ('imputer', SimpleImputer()),\n",
              "                                       ('tree',\n",
              "                                        DecisionTreeClassifier(max_depth=3,\n",
              "                                                               random_state=0))]),\n",
              "             n_jobs=-1, param_grid={'tree__max_depth': [3, 4, 5]})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# qual o melhor parâmetro\n",
        "grid.best_params_ "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vk_RCbxAjdwu",
        "outputId": "c174029c-39b7-4dd1-d5bb-39d80ac5915b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'tree__max_depth': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Pré-processando diferentes variáveis com ColumnTransfomer***"
      ],
      "metadata": {
        "id": "xBdYjVi4jkHL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ColumnTransformer(): Este transformador serve para especificar em qual coluna a transformação deve ser aplicada.\n",
        "\n"
      ],
      "metadata": {
        "id": "hhdALhc2kPbb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Claramente, você precisará de tratamentos diferentes para cada uma delas. Enquanto na primeira podemos preencher valores nulos com a mediana e normalizar os dados, para a segunda podemos preencher os valores nulos com o valor mais frequente."
      ],
      "metadata": {
        "id": "4QlacvzskXwl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer"
      ],
      "metadata": {
        "id": "op6rym5mjoAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pipeline para pré-processamento das variáveis Age e Fare\n",
        "num_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median'))\n",
        "])"
      ],
      "metadata": {
        "id": "yMCRmh5gjroe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pipeline para pré-processamento das variáveis Sex e Embarked\n",
        "cat_transformer = Pipeline(steps=[\n",
        "    ('one-hot encoder', OneHotEncoder())\n",
        "])\n"
      ],
      "metadata": {
        "id": "32c5EbHGjssj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compondo os pré-processadores\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('num', num_transformer, ['Age', 'Fare']),\n",
        "    ('cat', cat_transformer, ['Sex', 'Embarked'])\n",
        "])"
      ],
      "metadata": {
        "id": "ltgYFPHqjxgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# criando o modelo usando pipeline\n",
        "model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('tree', DecisionTreeClassifier(max_depth=3, random_state=0))\n",
        "])"
      ],
      "metadata": {
        "id": "A0uDeKmMjzgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tunando hiperparâmetros com 5-fold cross-validation e pipelines\n",
        "parameters = {'tree__max_depth': [3, 4, 5]}\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "grid = GridSearchCV(model, param_grid=parameters, cv=kfold, n_jobs=-1, return_train_score=True)\n",
        "grid.fit(X=df.drop(['Survived'], axis=1), y=df['Survived'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gjPsfJ_j1nF",
        "outputId": "98e035fb-6a37-41c1-b256-8ab0d54896af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),\n",
              "             estimator=Pipeline(steps=[('preprocessor',\n",
              "                                        ColumnTransformer(transformers=[('num',\n",
              "                                                                         Pipeline(steps=[('imputer',\n",
              "                                                                                          SimpleImputer(strategy='median'))]),\n",
              "                                                                         ['Age',\n",
              "                                                                          'Fare']),\n",
              "                                                                        ('cat',\n",
              "                                                                         Pipeline(steps=[('one-hot '\n",
              "                                                                                          'encoder',\n",
              "                                                                                          OneHotEncoder())]),\n",
              "                                                                         ['Sex',\n",
              "                                                                          'Embarked'])])),\n",
              "                                       ('tree',\n",
              "                                        DecisionTreeClassifier(max_depth=3,\n",
              "                                                               random_state=0))]),\n",
              "             n_jobs=-1, param_grid={'tree__max_depth': [3, 4, 5]},\n",
              "             return_train_score=True)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### O Pipeline permite que você passe pra ele até um pré-processador customizado, inteiramente construído para as suas necessidades."
      ],
      "metadata": {
        "id": "KQKd5rgsknpZ"
      }
    }
  ]
}